import streamlit as st
import torch
import numpy as np
from PIL import Image
import tempfile
import os
from datetime import datetime
import base64
from io import BytesIO
import subprocess
import shutil

# å®‰å…¨å¯¼å…¥ CLIP æ¨¡å‹
try:
    from transformers import CLIPProcessor, CLIPModel
except ImportError:
    try:
        # å¤‡é€‰ï¼šç›´æ¥å¯¼å…¥å¤„ç†å™¨
        from transformers.models.clip import CLIPProcessor, CLIPModel
    except ImportError:
        st.error("âŒ æ— æ³•å¯¼å…¥ CLIP æ¨¡å‹ã€‚è¯·è¿è¡Œ: pip install --upgrade transformers")
        st.stop()

# æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨
if shutil.which("ffmpeg") is None:
    st.error("âš ï¸ ç³»ç»Ÿæœªå®‰è£…ffmpegï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")

# ================= é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="ğŸ¬ è§†é¢‘æœç´¢å¼•æ“ - Video Search Engine",
    page_icon="ğŸ¬",
    layout="wide"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .main {
        background-color: #f5f7f9;
    }
    .stButton>button {
        width: 100%;
        background-color: #667eea;
        color: white;
        border: none;
        border-radius: 8px;
        height: 50px;
        font-size: 1.1em;
    }
    .stButton>button:hover {
        background-color: #764ba2;
    }
    h1 {
        color: #2c3e50;
        text-align: center;
    }
    h3 {
        color: #667eea;
    }
</style>
""", unsafe_allow_html=True)

# ================= æ¨¡å‹åŠ è½½ (ç¼“å­˜) =================
@st.cache_resource
def load_model():
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        st.info(f"ğŸ“± æ­£åœ¨ä½¿ç”¨ {device.upper()} è®¾å¤‡åŠ è½½æ¨¡å‹...")
        
        # åŠ è½½å¤„ç†å™¨ - å¸¦é‡è¯•å’Œå¤‡é€‰æ–¹æ¡ˆ
        st.info("åŠ è½½å¤„ç†å™¨ (Processor)...")
        try:
            processor = CLIPProcessor.from_pretrained(
                "openai/clip-vit-base-patch32",
                trust_remote_code=True,
                timeout=30
            )
        except Exception as e:
            st.warning(f"âš ï¸ å¤„ç†å™¨åŠ è½½å¤±è´¥ï¼Œå°è¯•å¤‡é€‰æ–¹æ¡ˆ: {str(e)}")
            # å¤‡é€‰ï¼šä½¿ç”¨è‡ªåŠ¨æ¨¡å‹ç±»
            from transformers import AutoProcessor
            processor = AutoProcessor.from_pretrained("openai/clip-vit-base-patch32")
        
        st.success("âœ“ å¤„ç†å™¨åŠ è½½æˆåŠŸ")
        
        # åŠ è½½æ¨¡å‹ - å¸¦é‡è¯•å’Œå¤‡é€‰æ–¹æ¡ˆ
        st.info("åŠ è½½CLIPæ¨¡å‹... (é¦–æ¬¡åŠ è½½éœ€è¦å‡ åˆ†é’Ÿ)")
        try:
            model = CLIPModel.from_pretrained(
                "openai/clip-vit-base-patch32",
                trust_remote_code=True,
                timeout=30
            )
        except Exception as e:
            st.warning(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°è¯•å¤‡é€‰æ–¹æ¡ˆ: {str(e)}")
            # å¤‡é€‰ï¼šä½¿ç”¨è‡ªåŠ¨æ¨¡å‹ç±»
            from transformers import AutoModel
            model = AutoModel.from_pretrained("openai/clip-vit-base-patch32")
        
        st.success("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # ç§»è‡³è®¾å¤‡
        st.info(f"å°†æ¨¡å‹ç§»è‡³ {device.upper()}...")
        model = model.to(device)
        st.success(f"âœ“ æ¨¡å‹å·²ç§»è‡³ {device.upper()}")
        
        # éªŒè¯æ¨¡å‹
        st.info("éªŒè¯æ¨¡å‹...")
        if hasattr(model, 'vision_model') and hasattr(model, 'text_model'):
            st.success("âœ“ æ¨¡å‹ç»“æ„æ­£ç¡®")
        else:
            st.warning("âš ï¸ æ¨¡å‹ç»“æ„ä¸æ ‡å‡†")
        
        return model, processor, device
    
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{str(e)}")
        import traceback
        st.error(f"è¿½è¸ª:\n{traceback.format_exc()}")
        return None, None, None

# ================= è§†é¢‘å¤„ç†å‡½æ•° =================
def extract_frames(video_file, interval=1):
    """ä»è§†é¢‘æ–‡ä»¶ä¸­æå–å¸§ï¼ˆä½¿ç”¨ffmpegï¼‰"""
    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
        tmp_file.write(video_file.read())
        tmp_path = tmp_file.name
    
    # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
    output_dir = tempfile.mkdtemp()
    
    try:
        # ä½¿ç”¨ffmpegæå–å¸§
        # fps=1/interval è¡¨ç¤ºæ¯éš”intervalç§’æå–ä¸€å¸§
        cmd = [
            'ffmpeg',
            '-i', tmp_path,
            '-vf', f'fps=1/{interval}',
            '-q:v', '2',
            os.path.join(output_dir, 'frame_%04d.jpg'),
            '-loglevel', 'error'
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            st.error(f"âŒ è§†é¢‘å¤„ç†å¤±è´¥: {result.stderr}")
            return None, None
        
        # è¯»å–æå–çš„å¸§
        frames = []
        timestamps = []
        frame_files = sorted([f for f in os.listdir(output_dir) if f.endswith('.jpg')])
        
        for idx, frame_file in enumerate(frame_files):
            frame_path = os.path.join(output_dir, frame_file)
            try:
                img = Image.open(frame_path)
                frames.append(img)
                timestamps.append(idx * interval)
            except Exception as e:
                st.warning(f"âš ï¸ æ— æ³•è¯»å–å¸§ {frame_file}")
                continue
        
        if not frames:
            st.error("âŒ æ— æ³•ä»è§†é¢‘ä¸­æå–ä»»ä½•å¸§")
            return None, None
        
        return frames, timestamps
    
    except FileNotFoundError:
        st.error("âŒ ffmpeg æœªå®‰è£…ã€‚è¯·å®‰è£… ffmpeg æˆ–ä½¿ç”¨äº‘ç«¯éƒ¨ç½²ç‰ˆæœ¬ã€‚")
        return None, None
    
    except Exception as e:
        st.error(f"âŒ å¤„ç†è§†é¢‘æ—¶å‡ºé”™: {str(e)}")
        return None, None
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
            if os.path.exists(output_dir):
                import shutil
                shutil.rmtree(output_dir)
        except:
            pass

def search_frames(model, processor, search_text, frames, timestamps, device):
    """æœç´¢æœ€åŒ¹é…çš„å¸§"""
    try:
        # éªŒè¯è¾“å…¥
        if not frames or len(frames) == 0:
            st.error("âŒ æ²¡æœ‰æå–åˆ°ä»»ä½•å¸§")
            return []
        
        if not search_text or search_text.strip() == "":
            st.error("âŒ æœç´¢è¯ä¸èƒ½ä¸ºç©º")
            return []
        
        # å¤„ç†è¾“å…¥
        try:
            inputs = processor(
                text=[search_text],
                images=frames,
                return_tensors="pt",
                padding=True
            )
        except Exception as e:
            st.error(f"âŒ å¤„ç†å™¨é”™è¯¯: {str(e)}")
            return []
        
        # ç§»è‡³è®¾å¤‡
        try:
            inputs = inputs.to(device)
        except Exception as e:
            st.error(f"âŒ è®¾å¤‡è½¬ç§»å¤±è´¥: {str(e)}")
            return []
        
        # æ¨ç†
        try:
            with torch.no_grad():
                outputs = model(**inputs)
        except Exception as e:
            st.error(f"âŒ æ¨¡å‹æ¨ç†å¤±è´¥: {str(e)}")
            return []
        
        # æ£€æŸ¥è¾“å‡º
        if outputs is None or outputs.logits_per_image is None:
            st.error("âŒ æ¨¡å‹æ²¡æœ‰è¿”å›æœ‰æ•ˆçš„è¾“å‡º")
            return []
        
        # logits_per_image shape: [num_images, 1]
        logits_per_image = outputs.logits_per_image
        
        # è°ƒè¯•ä¿¡æ¯
        st.info(f"ğŸ“Š Debug: logits_per_image å½¢çŠ¶ = {logits_per_image.shape}, å€¼ = {logits_per_image.squeeze().tolist()[:3]}...")
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰logitséƒ½ç›¸ç­‰
        unique_logits = torch.unique(logits_per_image)
        if len(unique_logits) == 1:
            st.warning("âš ï¸ è­¦å‘Š: æ‰€æœ‰logitsç›¸ç­‰ï¼Œæ¨¡å‹å¯èƒ½æœªæ­£ç¡®å­¦ä¹ ")
        
        # æŒ¤å‹ç»´åº¦
        try:
            logits_per_image = logits_per_image.squeeze(-1)  # [num_images, 1] â†’ [num_images]
        except Exception as e:
            st.error(f"âŒ squeezeå¤±è´¥: {str(e)}")
            return []
        
        # åº”ç”¨softmax
        try:
            import torch.nn.functional as F
            probs = F.softmax(logits_per_image, dim=0)
        except Exception as e:
            st.error(f"âŒ softmaxå¤±è´¥: {str(e)}")
            return []
        
        # éªŒè¯æ¦‚ç‡
        prob_sum = probs.sum().item()
        if abs(prob_sum - 1.0) > 0.01:
            st.warning(f"âš ï¸ æ¦‚ç‡å’Œ = {prob_sum:.4f}ï¼ˆåº”è¯¥â‰ˆ1.0ï¼‰")
        
        # è·å–Top-5ç»“æœ
        k = min(5, len(frames))
        if k == 1:
            # å¦‚æœåªæœ‰1å¼ å›¾ï¼Œç›´æ¥è¿”å›
            top5_probs = probs.unsqueeze(0)
            top5_indices = torch.tensor([0]).to(device)
        else:
            try:
                top5_probs, top5_indices = torch.topk(probs, k=k)
            except Exception as e:
                st.error(f"âŒ topkå¤±è´¥: {str(e)}")
                return []
        
        # æ„å»ºç»“æœ
        results = []
        for prob, idx in zip(top5_probs, top5_indices):
            results.append({
                'frame': frames[idx.item()],
                'timestamp': timestamps[idx.item()],
                'score': prob.item()
            })
        
        return results
    
    except Exception as e:
        st.error(f"âŒ æœç´¢å‡½æ•°å‡ºé”™: {str(e)}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")
        return []

def format_time(seconds):
    """æ ¼å¼åŒ–æ—¶é—´"""
    mins = int(seconds // 60)
    secs = int(seconds % 60)
    ms = int((seconds % 1) * 1000)
    return f"{mins}:{secs:02d}"

# ================= ä¸»åº”ç”¨ =================
st.title("ğŸ¬ æ™ºèƒ½è§†é¢‘æœç´¢å¼•æ“")
st.markdown("### ä¸Šä¼ è§†é¢‘ï¼Œç”¨è‡ªç„¶è¯­è¨€æè¿°æ‰¾åˆ°ä½ æƒ³è¦çš„ç‰‡æ®µ")

# åŠ è½½æ¨¡å‹
model, processor, device = load_model()

# æ£€æŸ¥æ¨¡å‹æ˜¯å¦æˆåŠŸåŠ è½½
if model is None or processor is None:
    st.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œåº”ç”¨æ— æ³•ç»§ç»­")
    st.stop()

st.success(f"âœ… æ¨¡å‹å·²åŠ è½½ (è¿è¡Œåœ¨ {device.upper()})")

# å¿«é€ŸéªŒè¯æ¨¡å‹
try:
    st.info("ğŸ” éªŒè¯æ¨¡å‹å¯ç”¨æ€§...")
    from PIL import Image
    test_img = Image.new('RGB', (224, 224), (100, 100, 100))
    test_inputs = processor(text=["test"], images=[test_img], return_tensors="pt", padding=True).to(device)
    with torch.no_grad():
        test_outputs = model(**test_inputs)
    if test_outputs and test_outputs.logits_per_image is not None:
        st.success("âœ“ æ¨¡å‹éªŒè¯é€šè¿‡")
    else:
        st.error("âŒ æ¨¡å‹éªŒè¯å¤±è´¥ï¼šè¾“å‡ºæ— æ•ˆ")
        st.stop()
except Exception as e:
    st.error(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {str(e)}")
    st.stop()

# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    st.markdown("---")
    st.subheader("âš™ï¸ è®¾ç½®")
    
    interval = st.slider(
        "å¸§æå–é—´éš” (ç§’)",
        min_value=1,
        max_value=10,
        value=2,
        help="æ¯éš”å¤šå°‘ç§’æå–ä¸€å¸§ã€‚è¾ƒå°çš„å€¼æ›´ç²¾ç¡®ä½†é€Ÿåº¦æ›´æ…¢"
    )
    
    st.markdown("---")
    st.markdown("### ğŸ’¡ ä½¿ç”¨æç¤º")
    st.info(
        """
        1. ä¸Šä¼ MP4æ ¼å¼çš„è§†é¢‘æ–‡ä»¶
        2. è¾“å…¥è¦æœç´¢çš„å†…å®¹æè¿°ï¼ˆè‹±æ–‡æ•ˆæœæ›´å¥½ï¼‰
        3. ç‚¹å‡»æœç´¢ï¼Œè·å–Top-5åŒ¹é…ç»“æœ
        4. æ¯ä¸ªç»“æœæ˜¾ç¤ºæ—¶é—´ç‚¹å’Œç½®ä¿¡åº¦
        """
    )

# ä¸»åº”ç”¨åŒºåŸŸ
col1, col2 = st.columns([1, 2])

with col1:
    st.markdown("### ğŸ“¤ ä¸Šä¼ è§†é¢‘")
    uploaded_file = st.file_uploader(
        "é€‰æ‹©è§†é¢‘æ–‡ä»¶ (MP4, AVI, MOV)",
        type=["mp4", "avi", "mov", "mkv"],
        help="è§†é¢‘æ–‡ä»¶å¤§å°é™åˆ¶æ ¹æ®æœåŠ¡å™¨è€Œå®š"
    )

with col2:
    st.markdown("### ğŸ” æœç´¢æè¿°")
    search_text = st.text_input(
        "è¾“å…¥ä½ è¦æœç´¢çš„å†…å®¹",
        placeholder="ä¾‹å¦‚: 'A cat sleeping' æˆ– 'Ball entering goal'",
        help="ä½¿ç”¨è‹±æ–‡æè¿°æ•ˆæœæœ€ä½³"
    )

# å¤„ç†ä¸Šä¼ å’Œæœç´¢
if uploaded_file and search_text:
    st.markdown("---")
    
    # æå–è§†é¢‘å¸§
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    status_text.text("ğŸ“¹ æ­£åœ¨æå–è§†é¢‘å¸§...")
    frames, timestamps = extract_frames(uploaded_file, interval=interval)
    progress_bar.progress(30)
    
    if frames is None:
        st.stop()
    
    status_text.text(f"âœ… æˆåŠŸæå– {len(frames)} å¸§")
    progress_bar.progress(60)
    
    # æœç´¢
    status_text.text("ğŸ” æ­£åœ¨æœç´¢åŒ¹é…çš„å¸§...")
    results = search_frames(model, processor, search_text, frames, timestamps, device)
    progress_bar.progress(100)
    
    status_text.text("âœ… æœç´¢å®Œæˆï¼")
    
    # æ˜¾ç¤ºç»“æœ
    st.markdown("---")
    st.markdown(f"## ğŸ¯ æœç´¢ç»“æœ")
    st.markdown(f"**æœç´¢è¯:** \"{search_text}\" | **æå–å¸§æ•°:** {len(frames)} | **å¤„ç†é—´éš”:** {interval}ç§’")
    
    # æ˜¾ç¤ºTop-5ç»“æœ
    for idx, result in enumerate(results, 1):
        with st.container():
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.image(result['frame'], use_container_width=True)
            
            with col2:
                st.markdown(f"### #{idx} ç»“æœ")
                st.markdown(f"**â±ï¸ æ—¶é—´:** {format_time(result['timestamp'])}")
                
                # ç½®ä¿¡åº¦æŒ‡æ ‡
                confidence = result['score']
                st.markdown(f"**ğŸ“Š ç½®ä¿¡åº¦:** {confidence*100:.1f}%")
                st.progress(confidence)
                
                # ä¸‹è½½æŒ‰é’®
                img_bytes = BytesIO()
                result['frame'].save(img_bytes, format='PNG')
                img_bytes.seek(0)
                
                st.download_button(
                    label=f"â¬‡ï¸ ä¸‹è½½ç¬¬{idx}ä¸ªç»“æœ",
                    data=img_bytes,
                    file_name=f"search_result_{idx}_at_{format_time(result['timestamp'])}.png",
                    mime="image/png"
                )
            
            st.markdown("---")
    
    # ç”ŸæˆHTMLæŠ¥å‘Š
    st.markdown("## ğŸ“Š ç”ŸæˆæŠ¥å‘Š")
    
    if st.button("ğŸ“„ ç”ŸæˆHTMLæŠ¥å‘Š"):
        # åˆ›å»ºHTMLå†…å®¹
        results_html = ""
        for idx, result in enumerate(results, 1):
            img_bytes = BytesIO()
            result['frame'].save(img_bytes, format='PNG')
            img_base64 = base64.b64encode(img_bytes.getvalue()).decode()
            
            results_html += f"""
            <div style="background: #f9f9f9; padding: 20px; margin: 20px 0; border-radius: 10px; border-left: 4px solid #667eea;">
                <h3>ç»“æœ #{idx}</h3>
                <img src="data:image/png;base64,{img_base64}" style="max-width: 100%; border-radius: 8px; margin: 10px 0;">
                <p><strong>â±ï¸ æ—¶é—´:</strong> {format_time(result['timestamp'])}</p>
                <p><strong>ğŸ“Š ç½®ä¿¡åº¦:</strong> {result['score']*100:.2f}%</p>
                <div style="background: #e0e0e0; height: 8px; border-radius: 4px; margin: 10px 0; overflow: hidden;">
                    <div style="background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); height: 100%; width: {result['score']*100}%;"></div>
                </div>
            </div>
            """
        
        html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è§†é¢‘æœç´¢ç»“æœæŠ¥å‘Š</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            margin: 0;
            padding: 20px;
            min-height: 100vh;
        }}
        .container {{
            background: white;
            border-radius: 15px;
            padding: 40px;
            max-width: 1000px;
            margin: 0 auto;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        }}
        .header {{
            text-align: center;
            margin-bottom: 30px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 20px;
        }}
        .header h1 {{
            color: #667eea;
            margin: 0;
        }}
        .header p {{
            color: #999;
            margin: 10px 0 0 0;
        }}
        .search-info {{
            background: #f0f4ff;
            border-left: 5px solid #667eea;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }}
        .footer {{
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #eee;
            color: #999;
            font-size: 0.9em;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¬ è§†é¢‘æœç´¢ç»“æœæŠ¥å‘Š</h1>
            <p>ç”Ÿæˆäº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        
        <div class="search-info">
            <strong>ğŸ” æœç´¢è¯:</strong> "{search_text}"<br>
            <strong>ğŸ“Š æå–å¸§æ•°:</strong> {len(frames)}<br>
            <strong>âš™ï¸ å¤„ç†é—´éš”:</strong> {interval}ç§’
        </div>
        
        <h2>ğŸ“‹ Top-5 åŒ¹é…ç»“æœ</h2>
        {results_html}
        
        <div class="footer">
            <p>ç”± CLIP è§†é¢‘æœç´¢å¼•æ“ç”Ÿæˆ</p>
        </div>
    </div>
</body>
</html>"""
        
        # ä¸‹è½½æŠ¥å‘Š
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½HTMLæŠ¥å‘Š",
            data=html_content,
            file_name=f"video_search_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
            mime="text/html"
        )
        st.success("âœ… æŠ¥å‘Šå·²å‡†å¤‡å¥½ä¸‹è½½ï¼")

else:
    # æ¬¢è¿ç•Œé¢
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        ### ğŸ“¹ åŠŸèƒ½ç‰¹ç‚¹
        - ğŸ¥ æ”¯æŒå¤šç§è§†é¢‘æ ¼å¼
        - âš¡ ç§’çº§å“åº”é€Ÿåº¦
        - ğŸ¤– åŸºäºCLIPæ·±åº¦å­¦ä¹ 
        - ğŸ“Š å¤šç»“æœæ’åæ˜¾ç¤º
        """)
    
    with col2:
        st.markdown("""
        ### ğŸ”§ å¦‚ä½•ä½¿ç”¨
        1. ä¸Šä¼ è§†é¢‘æ–‡ä»¶
        2. è¾“å…¥æœç´¢æè¿°
        3. ç‚¹å‡»æœç´¢
        4. æŸ¥çœ‹Top-5ç»“æœ
        5. ä¸‹è½½æŠ¥å‘Š
        """)
    
    with col3:
        st.markdown("""
        ### ğŸ’¡ æœç´¢å»ºè®®
        - ä½¿ç”¨è‹±æ–‡æ•ˆæœæœ€ä½³
        - ç®€æ´æ¸…æ™°çš„æè¿°
        - å…·ä½“çš„è§†è§‰ç‰¹å¾
        - ä¾‹: "soccer goal"
        """)

# é¡µè„š
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #999; padding: 20px;">
    <p>ğŸ¬ æ™ºèƒ½è§†é¢‘æœç´¢å¼•æ“ | ç”± OpenAI CLIP æä¾›æ”¯æŒ</p>
    <p>å¯éƒ¨ç½²åˆ° Streamlit Cloud / Hugging Face Spaces / äº‘æœåŠ¡å™¨</p>
</div>
""", unsafe_allow_html=True)
