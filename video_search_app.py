import streamlit as st
import torch
import numpy as np
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
import tempfile
import os
from datetime import datetime
import base64
from io import BytesIO
import subprocess
import shutil

# æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨
if shutil.which("ffmpeg") is None:
    st.error("âš ï¸ ç³»ç»Ÿæœªå®‰è£…ffmpegï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")

# ================= é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="ğŸ¬ è§†é¢‘æœç´¢å¼•æ“ - Video Search Engine",
    page_icon="ğŸ¬",
    layout="wide"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .main {
        background-color: #f5f7f9;
    }
    .stButton>button {
        width: 100%;
        background-color: #667eea;
        color: white;
        border: none;
        border-radius: 8px;
        height: 50px;
        font-size: 1.1em;
    }
    .stButton>button:hover {
        background-color: #764ba2;
    }
    h1 {
        color: #2c3e50;
        text-align: center;
    }
    h3 {
        color: #667eea;
    }
</style>
""", unsafe_allow_html=True)

# ================= æ¨¡å‹åŠ è½½ (ç¼“å­˜) =================
@st.cache_resource
def load_model():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    with st.spinner("ğŸ”„ æ­£åœ¨åŠ è½½CLIPæ¨¡å‹... (åˆæ¬¡åŠ è½½éœ€è¦å‡ åˆ†é’Ÿ)"):
        model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
        processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
    return model, processor, device

# ================= è§†é¢‘å¤„ç†å‡½æ•° =================
def extract_frames(video_file, interval=1):
    """ä»è§†é¢‘æ–‡ä»¶ä¸­æå–å¸§ï¼ˆä½¿ç”¨ffmpegï¼‰"""
    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
        tmp_file.write(video_file.read())
        tmp_path = tmp_file.name
    
    # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
    output_dir = tempfile.mkdtemp()
    
    try:
        # ä½¿ç”¨ffmpegæå–å¸§
        # fps=1/interval è¡¨ç¤ºæ¯éš”intervalç§’æå–ä¸€å¸§
        cmd = [
            'ffmpeg',
            '-i', tmp_path,
            '-vf', f'fps=1/{interval}',
            '-q:v', '2',
            os.path.join(output_dir, 'frame_%04d.jpg'),
            '-loglevel', 'error'
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            st.error(f"âŒ è§†é¢‘å¤„ç†å¤±è´¥: {result.stderr}")
            return None, None
        
        # è¯»å–æå–çš„å¸§
        frames = []
        timestamps = []
        frame_files = sorted([f for f in os.listdir(output_dir) if f.endswith('.jpg')])
        
        for idx, frame_file in enumerate(frame_files):
            frame_path = os.path.join(output_dir, frame_file)
            try:
                img = Image.open(frame_path)
                frames.append(img)
                timestamps.append(idx * interval)
            except Exception as e:
                st.warning(f"âš ï¸ æ— æ³•è¯»å–å¸§ {frame_file}")
                continue
        
        if not frames:
            st.error("âŒ æ— æ³•ä»è§†é¢‘ä¸­æå–ä»»ä½•å¸§")
            return None, None
        
        return frames, timestamps
    
    except FileNotFoundError:
        st.error("âŒ ffmpeg æœªå®‰è£…ã€‚è¯·å®‰è£… ffmpeg æˆ–ä½¿ç”¨äº‘ç«¯éƒ¨ç½²ç‰ˆæœ¬ã€‚")
        return None, None
    
    except Exception as e:
        st.error(f"âŒ å¤„ç†è§†é¢‘æ—¶å‡ºé”™: {str(e)}")
        return None, None
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
            if os.path.exists(output_dir):
                import shutil
                shutil.rmtree(output_dir)
        except:
            pass

def search_frames(model, processor, search_text, frames, timestamps, device):
    """æœç´¢æœ€åŒ¹é…çš„å¸§"""
    inputs = processor(
        text=[search_text],
        images=frames,
        return_tensors="pt",
        padding=True
    ).to(device)
    
    with torch.no_grad():
        outputs = model(**inputs)
    
    logits_per_image = outputs.logits_per_image
    probs = logits_per_image.softmax(dim=0)
    
    # è·å–Top-5ç»“æœ
    top5_probs, top5_indices = torch.topk(probs.squeeze(), k=min(5, len(frames)))
    
    results = []
    for prob, idx in zip(top5_probs, top5_indices):
        results.append({
            'frame': frames[idx.item()],
            'timestamp': timestamps[idx.item()],
            'score': prob.item()
        })
    
    return results

def format_time(seconds):
    """æ ¼å¼åŒ–æ—¶é—´"""
    mins = int(seconds // 60)
    secs = int(seconds % 60)
    ms = int((seconds % 1) * 1000)
    return f"{mins}:{secs:02d}"

# ================= ä¸»åº”ç”¨ =================
st.title("ğŸ¬ æ™ºèƒ½è§†é¢‘æœç´¢å¼•æ“")
st.markdown("### ä¸Šä¼ è§†é¢‘ï¼Œç”¨è‡ªç„¶è¯­è¨€æè¿°æ‰¾åˆ°ä½ æƒ³è¦çš„ç‰‡æ®µ")

# åŠ è½½æ¨¡å‹
model, processor, device = load_model()
st.success(f"âœ… æ¨¡å‹å·²åŠ è½½ (è¿è¡Œåœ¨ {device.upper()})")

# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    st.markdown("---")
    st.subheader("âš™ï¸ è®¾ç½®")
    
    interval = st.slider(
        "å¸§æå–é—´éš” (ç§’)",
        min_value=1,
        max_value=10,
        value=2,
        help="æ¯éš”å¤šå°‘ç§’æå–ä¸€å¸§ã€‚è¾ƒå°çš„å€¼æ›´ç²¾ç¡®ä½†é€Ÿåº¦æ›´æ…¢"
    )
    
    st.markdown("---")
    st.markdown("### ğŸ’¡ ä½¿ç”¨æç¤º")
    st.info(
        """
        1. ä¸Šä¼ MP4æ ¼å¼çš„è§†é¢‘æ–‡ä»¶
        2. è¾“å…¥è¦æœç´¢çš„å†…å®¹æè¿°ï¼ˆè‹±æ–‡æ•ˆæœæ›´å¥½ï¼‰
        3. ç‚¹å‡»æœç´¢ï¼Œè·å–Top-5åŒ¹é…ç»“æœ
        4. æ¯ä¸ªç»“æœæ˜¾ç¤ºæ—¶é—´ç‚¹å’Œç½®ä¿¡åº¦
        """
    )

# ä¸»åº”ç”¨åŒºåŸŸ
col1, col2 = st.columns([1, 2])

with col1:
    st.markdown("### ğŸ“¤ ä¸Šä¼ è§†é¢‘")
    uploaded_file = st.file_uploader(
        "é€‰æ‹©è§†é¢‘æ–‡ä»¶ (MP4, AVI, MOV)",
        type=["mp4", "avi", "mov", "mkv"],
        help="è§†é¢‘æ–‡ä»¶å¤§å°é™åˆ¶æ ¹æ®æœåŠ¡å™¨è€Œå®š"
    )

with col2:
    st.markdown("### ğŸ” æœç´¢æè¿°")
    search_text = st.text_input(
        "è¾“å…¥ä½ è¦æœç´¢çš„å†…å®¹",
        placeholder="ä¾‹å¦‚: 'A cat sleeping' æˆ– 'Ball entering goal'",
        help="ä½¿ç”¨è‹±æ–‡æè¿°æ•ˆæœæœ€ä½³"
    )

# å¤„ç†ä¸Šä¼ å’Œæœç´¢
if uploaded_file and search_text:
    st.markdown("---")
    
    # æå–è§†é¢‘å¸§
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    status_text.text("ğŸ“¹ æ­£åœ¨æå–è§†é¢‘å¸§...")
    frames, timestamps = extract_frames(uploaded_file, interval=interval)
    progress_bar.progress(30)
    
    if frames is None:
        st.stop()
    
    status_text.text(f"âœ… æˆåŠŸæå– {len(frames)} å¸§")
    progress_bar.progress(60)
    
    # æœç´¢
    status_text.text("ğŸ” æ­£åœ¨æœç´¢åŒ¹é…çš„å¸§...")
    results = search_frames(model, processor, search_text, frames, timestamps, device)
    progress_bar.progress(100)
    
    status_text.text("âœ… æœç´¢å®Œæˆï¼")
    
    # æ˜¾ç¤ºç»“æœ
    st.markdown("---")
    st.markdown(f"## ğŸ¯ æœç´¢ç»“æœ")
    st.markdown(f"**æœç´¢è¯:** \"{search_text}\" | **æå–å¸§æ•°:** {len(frames)} | **å¤„ç†é—´éš”:** {interval}ç§’")
    
    # æ˜¾ç¤ºTop-5ç»“æœ
    for idx, result in enumerate(results, 1):
        with st.container():
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.image(result['frame'], width='stretch')
            
            with col2:
                st.markdown(f"### #{idx} ç»“æœ")
                st.markdown(f"**â±ï¸ æ—¶é—´:** {format_time(result['timestamp'])}")
                
                # ç½®ä¿¡åº¦æŒ‡æ ‡
                confidence = result['score']
                st.markdown(f"**ğŸ“Š ç½®ä¿¡åº¦:** {confidence*100:.1f}%")
                st.progress(confidence)
                
                # ä¸‹è½½æŒ‰é’®
                img_bytes = BytesIO()
                result['frame'].save(img_bytes, format='PNG')
                img_bytes.seek(0)
                
                st.download_button(
                    label=f"â¬‡ï¸ ä¸‹è½½ç¬¬{idx}ä¸ªç»“æœ",
                    data=img_bytes,
                    file_name=f"search_result_{idx}_at_{format_time(result['timestamp'])}.png",
                    mime="image/png"
                )
            
            st.markdown("---")
    
    # ç”ŸæˆHTMLæŠ¥å‘Š
    st.markdown("## ğŸ“Š ç”ŸæˆæŠ¥å‘Š")
    
    if st.button("ğŸ“„ ç”ŸæˆHTMLæŠ¥å‘Š"):
        # åˆ›å»ºHTMLå†…å®¹
        results_html = ""
        for idx, result in enumerate(results, 1):
            img_bytes = BytesIO()
            result['frame'].save(img_bytes, format='PNG')
            img_base64 = base64.b64encode(img_bytes.getvalue()).decode()
            
            results_html += f"""
            <div style="background: #f9f9f9; padding: 20px; margin: 20px 0; border-radius: 10px; border-left: 4px solid #667eea;">
                <h3>ç»“æœ #{idx}</h3>
                <img src="data:image/png;base64,{img_base64}" style="max-width: 100%; border-radius: 8px; margin: 10px 0;">
                <p><strong>â±ï¸ æ—¶é—´:</strong> {format_time(result['timestamp'])}</p>
                <p><strong>ğŸ“Š ç½®ä¿¡åº¦:</strong> {result['score']*100:.2f}%</p>
                <div style="background: #e0e0e0; height: 8px; border-radius: 4px; margin: 10px 0; overflow: hidden;">
                    <div style="background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); height: 100%; width: {result['score']*100}%;"></div>
                </div>
            </div>
            """
        
        html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è§†é¢‘æœç´¢ç»“æœæŠ¥å‘Š</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            margin: 0;
            padding: 20px;
            min-height: 100vh;
        }}
        .container {{
            background: white;
            border-radius: 15px;
            padding: 40px;
            max-width: 1000px;
            margin: 0 auto;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        }}
        .header {{
            text-align: center;
            margin-bottom: 30px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 20px;
        }}
        .header h1 {{
            color: #667eea;
            margin: 0;
        }}
        .header p {{
            color: #999;
            margin: 10px 0 0 0;
        }}
        .search-info {{
            background: #f0f4ff;
            border-left: 5px solid #667eea;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }}
        .footer {{
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #eee;
            color: #999;
            font-size: 0.9em;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¬ è§†é¢‘æœç´¢ç»“æœæŠ¥å‘Š</h1>
            <p>ç”Ÿæˆäº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        
        <div class="search-info">
            <strong>ğŸ” æœç´¢è¯:</strong> "{search_text}"<br>
            <strong>ğŸ“Š æå–å¸§æ•°:</strong> {len(frames)}<br>
            <strong>âš™ï¸ å¤„ç†é—´éš”:</strong> {interval}ç§’
        </div>
        
        <h2>ğŸ“‹ Top-5 åŒ¹é…ç»“æœ</h2>
        {results_html}
        
        <div class="footer">
            <p>ç”± CLIP è§†é¢‘æœç´¢å¼•æ“ç”Ÿæˆ</p>
        </div>
    </div>
</body>
</html>"""
        
        # ä¸‹è½½æŠ¥å‘Š
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½HTMLæŠ¥å‘Š",
            data=html_content,
            file_name=f"video_search_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
            mime="text/html"
        )
        st.success("âœ… æŠ¥å‘Šå·²å‡†å¤‡å¥½ä¸‹è½½ï¼")

else:
    # æ¬¢è¿ç•Œé¢
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        ### ğŸ“¹ åŠŸèƒ½ç‰¹ç‚¹
        - ğŸ¥ æ”¯æŒå¤šç§è§†é¢‘æ ¼å¼
        - âš¡ ç§’çº§å“åº”é€Ÿåº¦
        - ğŸ¤– åŸºäºCLIPæ·±åº¦å­¦ä¹ 
        - ğŸ“Š å¤šç»“æœæ’åæ˜¾ç¤º
        """)
    
    with col2:
        st.markdown("""
        ### ğŸ”§ å¦‚ä½•ä½¿ç”¨
        1. ä¸Šä¼ è§†é¢‘æ–‡ä»¶
        2. è¾“å…¥æœç´¢æè¿°
        3. ç‚¹å‡»æœç´¢
        4. æŸ¥çœ‹Top-5ç»“æœ
        5. ä¸‹è½½æŠ¥å‘Š
        """)
    
    with col3:
        st.markdown("""
        ### ğŸ’¡ æœç´¢å»ºè®®
        - ä½¿ç”¨è‹±æ–‡æ•ˆæœæœ€ä½³
        - ç®€æ´æ¸…æ™°çš„æè¿°
        - å…·ä½“çš„è§†è§‰ç‰¹å¾
        - ä¾‹: "soccer goal"
        """)

# é¡µè„š
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #999; padding: 20px;">
    <p>ğŸ¬ æ™ºèƒ½è§†é¢‘æœç´¢å¼•æ“ | ç”± OpenAI CLIP æä¾›æ”¯æŒ</p>
    <p>å¯éƒ¨ç½²åˆ° Streamlit Cloud / Hugging Face Spaces / äº‘æœåŠ¡å™¨</p>
</div>
""", unsafe_allow_html=True)
